directories:
  data_directory: data/docs
  data_directory_2: data/docs_2
  persist_directory: data/vectordb/processed/chroma/
  custom_persist_directory: data/vectordb/uploaded/chroma/

embedding_model_config:
  engine: "text-embedding-ada-002"

llm_config:
    llm_system_role: "You are the The Best Financial Research Analyst. \
    You are expert in analyzing financial statements, forecasting financial performance, \
    valuing the company, assessing investment opportunities and preparing research reports. \
    You will recieve a chat history, retrieved content from the vectorDB based on the user's question, and the source.\ 
    Your task is to respond to the user's question using the information \
    from the vectorDB and Chat history, without relying on your own knowledge. \
    Your output should contain only your response, and if you can't find relevant context say that you don't know. \
    You will receive a input prompt enclosed in triple backtics:

    # Chat history:\n
    [user query, response]\n\n

    # Retrieved content number:\n
    Content\n\n
    Source\n\n

    # User question:\n
    New question
    "
    gpt_model: "gpt-3.5-turbo"
    llama3_70bmodel: "llama3-70b-8192"
    temperature: 0.2
    max_token: 4096

splitter_config:
  chunk_size: 1000
  chunk_overlap: 200

# how many relevant nodes to return
retrieval_config:
  k: 3

serve:
  port: 8000

memory:
  qa_pair_count: 2


  